apiVersion: pgv2.percona.com/v2
kind: PerconaPGCluster
metadata:
  name: plantsuite-ppgc
#  annotations:
#    test-annotation: value
#  finalizers:
#  - percona.com/delete-pvc
#  - percona.com/delete-ssl
#  - percona.com/delete-backups
spec:
  crVersion: 2.8.0
#  initContainer:
#    image: docker.io/percona/percona-postgresql-operator:2.8.0
#    resources:
#      limits:
#        cpu: 2.0
#        memory: 4Gi
#      requests:
#        cpu: 1.0
#        memory: 3Gi
#    containerSecurityContext:
#      runAsUser: 1001
#      runAsGroup: 1001
#      runAsNonRoot: true
#      privileged: false
#      allowPrivilegeEscalation: false
#      readOnlyRootFilesystem: true
#      capabilities:
#        add:
#          - NET_ADMIN
#          - SYS_TIME
#        drop:
#          - ALL
#      seccompProfile:
#        type: Localhost
#        localhostProfile: localhost/profile.json
#      procMount: Default
#      seLinuxOptions:
#        type: spc_t
#        level: s0:c123,c456
#  metadata:
#    annotations:
#      example-annotation: value
#    labels:
#      example-label: value
#  secrets:
#    customRootCATLSSecret:
#      name: plantsuite-ppgc-ca-cert
#      items:
#        - key: "tls.crt"
#          path: "root.crt"
#        - key: "tls.key"
#          path: "root.key"
#    customTLSSecret:
#      name: plantsuite-ppgc-cert
#    customReplicationTLSSecret:
#      name: replication1-cert
#  tlsOnly: false

#  standby:
#    enabled: true
#    host: "<primary-ip>"
#    port: "<primary-port>"
#    repoName: repo1

#  openshift: true

#  autoCreateUserSchema: true

#  users:
#    - name: rhino
#      databases:
#        - zoo
#      options: "SUPERUSER"
#      password:
#        type: ASCII
#      secretName: "rhino-credentials"
#      grantPublicSchemaAccess: false
  users:
    - name: keycloak
      databases:
        - keycloak

#  databaseInitSQL:
#    key: init.sql
#    name: plantsuite-ppgc-init-sql

#  pause: true
#  unmanaged: true
#  dataSource:
#    postgresCluster:
#      clusterName: plantsuite-ppgc
#      clusterNamespace: plantsuite-ppgc-namespace
#      repoName: repo1
#      options:
#      - --type=time
#      - --target="2021-06-09 14:15:11-04"
#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers
#    pgbackrest:
#      stanza: db
#      configuration:
#      - secret:
#          name: pgo-s3-creds
#      global:
#        repo1-path: /pgbackrest/postgres-operator/hippo/repo1
#      repo:
#        name: repo1
#        s3:
#          bucket: "my-bucket"
#          endpoint: "s3.ca-central-1.amazonaws.com"
#          region: "ca-central-1"
#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers
#    volumes:
#      pgDataVolume:
#        pvcName: plantsuite-ppgc
#        directory: plantsuite-ppgc
#        tolerations:
#        - effect: NoSchedule
#          key: role
#          operator: Equal
#          value: connection-poolers
#        annotations:
#          test-annotation: value
#        labels:
#          test-label: value
#      pgWALVolume:
#        pvcName: plantsuite-ppgc-pvc-name
#        directory: some-dir
#        tolerations:
#        - effect: NoSchedule
#          key: role
#          operator: Equal
#          value: connection-poolers
#        annotations:
#          test-annotation: value
#        labels:
#          test-label: value
#      pgBackRestVolume:
#        pvcName: plantsuite-ppgc-pgbr-repo
#        directory: plantsuite-ppgc-backrest-shared-repo
#        tolerations:
#        - effect: NoSchedule
#          key: role
#          operator: Equal
#          value: connection-poolers
#        annotations:
#          test-annotation: value
#        labels:
#          test-label: value


  image: docker.io/percona/percona-distribution-postgresql:17.6-1
  imagePullPolicy: IfNotPresent
  postgresVersion: 17
#  port: 5432

#  expose:
#    annotations:
#      my-annotation: value1
#    labels:
#      my-label: value2
#    type: LoadBalancer
#    loadBalancerClass: "eks.amazonaws.com/nlb"
#    loadBalancerSourceRanges:
#      - 10.0.0.0/8
#  exposeReplicas:
#    annotations:
#      my-annotation: value1
#    labels:
#      my-label: value2
#    type: LoadBalancer
#    loadBalancerClass: "eks.amazonaws.com/nlb"
#    loadBalancerSourceRanges:
#      - 10.0.0.0/8

  instances:
  - name: ins1
    replicas: 3
#    env:
#    - name: MY_ENV
#      value: "1000"
#    envFrom:
#    - secretRef:
#        name: instance-env-secret
#    initContainer:
#      image: docker.io/percona/percona-postgresql-operator:2.8.0
#      resources:
#        limits:
#          cpu: 2.0
#          memory: 4Gi
#      containerSecurityContext:
#        runAsUser: 1001
#        runAsGroup: 1001
#        runAsNonRoot: true
#        privileged: false
#        allowPrivilegeEscalation: false
#        readOnlyRootFilesystem: true
#        capabilities:
#          add:
#            - NET_ADMIN
#            - SYS_TIME
#          drop:
#            - ALL
#        seccompProfile:
#          type: Localhost
#          localhostProfile: localhost/profile.json
#        procMount: Default
#        seLinuxOptions:
#          type: spc_t
#          level: s0:c123,c456
#
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              postgres-operator.crunchydata.com/data: postgres
              postgres-operator.crunchydata.com/instance-set: ins1
          topologyKey: kubernetes.io/hostname
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 512Mi
#    containers:
#      replicaCertCopy:
#        resources:
#          limits:
#            cpu: 200m
#            memory: 128Mi
#          requests:
#            cpu: 100m
#            memory: 120Mi
#    sidecars:
#    - name: testcontainer
#      image: busybox:latest
#      command: ["sleep", "30d"]
#      securityContext: {}
#    - name: testcontainer2
#      image: mycontainer1:latest
#
#    topologySpreadConstraints:
#      - maxSkew: 1
#        topologyKey: my-node-label
#        whenUnsatisfiable: DoNotSchedule
#        labelSelector:
#          matchLabels:
#            postgres-operator.crunchydata.com/instance-set: ins1
#
#    tolerations:
#    - effect: NoSchedule
#      key: role
#      operator: Equal
#      value: connection-poolers
#
#    priorityClassName: high-priority
#
#    securityContext:
#      fsGroup: 1001
#      runAsUser: 1001
#      runAsNonRoot: true
#      fsGroupChangePolicy: "OnRootMismatch"
#      runAsGroup: 1001
#      seLinuxOptions:
#        type: spc_t
#        level: s0:c123,c456
#      seccompProfile:
#        type: Localhost
#        localhostProfile: localhost/profile.json
#      supplementalGroups:
#      - 1001
#      sysctls:
#      - name: net.ipv4.tcp_keepalive_time
#        value: "600"
#      - name: net.ipv4.tcp_keepalive_intvl
#        value: "60"
#
#    walVolumeClaimSpec:
#       storageClassName: standard
#       accessModes:
#       - ReadWriteOnce
#       resources:
#         requests:
#           storage: 1Gi
#
    dataVolumeClaimSpec:
#      storageClassName: standard
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
#      limits:
#          storage: 5Gi
#    tablespaceVolumes:
#      - name: user
#        dataVolumeClaimSpec:
#          accessModes:
#            - 'ReadWriteOnce'
#          resources:
#            requests:
#              storage: 1Gi

  proxy:
    pgBouncer:
      replicas: 3
      image: docker.io/percona/percona-pgbouncer:1.24.1-1
#      env:
#      - name: MY_ENV
#        value: "1000"
#      envFrom:
#      - secretRef:
#          name: pgbouncer-env-secret
#      exposeSuperusers: true
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 100m
          memory: 128Mi          
#      containers:
#        pgbouncerConfig:
#          resources:
#            limits:
#              cpu: 200m
#              memory: 128Mi
#            requests:
#              cpu: 150m
#              memory: 120Mi
#
#      expose:
#        annotations:
#          my-annotation: value1
#        labels:
#          my-label: value2
#        type: LoadBalancer
#        loadBalancerClass: "eks.amazonaws.com/nlb"
#        loadBalancerSourceRanges:
#          - 10.0.0.0/8
#
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  postgres-operator.crunchydata.com/role: pgbouncer
              topologyKey: kubernetes.io/hostname
#
#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers
#
#      securityContext:
#        fsGroup: 1001
#        runAsUser: 1001
#        runAsNonRoot: true
#        fsGroupChangePolicy: "OnRootMismatch"
#        runAsGroup: 1001
#        seLinuxOptions:
#          type: spc_t
#          level: s0:c123,c456
#        seccompProfile:
#          type: Localhost
#          localhostProfile: localhost/profile.json
#        supplementalGroups:
#        - 1001
#        sysctls:
#        - name: net.ipv4.tcp_keepalive_time
#          value: "600"
#        - name: net.ipv4.tcp_keepalive_intvl
#          value: "60"
#
#      topologySpreadConstraints:
#        - maxSkew: 1
#          topologyKey: kubernetes.io/hostname
#          whenUnsatisfiable: ScheduleAnyway
#          labelSelector:
#            matchLabels:
#              postgres-operator.crunchydata.com/role: pgbouncer
#
#      sidecars:
#      - name: bouncertestcontainer1
#        image: busybox:latest
#        command: ["sleep", "30d"]
#        securityContext: {}
#
#      customTLSSecret:
#        name: keycloakdb-pgbouncer.tls
#
      config:
        global:
          # configuração recomendada para keycloak
          # https://www.keycloak.org/high-availability/single-cluster/concepts-database-connections
          # https://www.keycloak.org/high-availability/single-cluster/deploy-keycloak
          pool_mode: session
          default_pool_size: "20"
          min_pool_size: "20"
          max_db_connections: "200"

  backups:
#    trackLatestRestorableTime: true
    pgbackrest:
#      metadata:
#        labels:
      image: docker.io/percona/percona-pgbackrest:2.56.0-1
#      env:
#      - name: MY_ENV
#        value: "1000"
#      envFrom:
#      - secretRef:
#          name: repo-host-env-secret
#      initContainer:
#        image: docker.io/percona/percona-postgresql-operator:2.8.0
#        resources:
#          limits:
#            cpu: 2.0
#            memory: 4Gi
#          requests:
#            cpu: 1.0
#            memory: 3Gi
#        containerSecurityContext:
#          runAsUser: 1001
#          runAsGroup: 1001
#          runAsNonRoot: true
#          privileged: false
#          allowPrivilegeEscalation: false
#          readOnlyRootFilesystem: true
#          capabilities:
#            add:
#              - NET_ADMIN
#              - SYS_TIME
#            drop:
#              - ALL
#          seccompProfile:
#            type: Localhost
#            localhostProfile: localhost/profile.json
#          procMount: Default
#          seLinuxOptions:
#            type: spc_t
#            level: s0:c123,c456
#      containers:
#        pgbackrest:
#          resources:
#            limits:
#              cpu: 200m
#              memory: 128Mi
#            requests:
#              cpu: 150m
#              memory: 120Mi
#        pgbackrestConfig:
#          resources:
#            limits:
#              cpu: 200m
#              memory: 128Mi
#            requests:
#              cpu: 150m
#              memory: 120Mi
#
#      configuration:
#        - secret:
#            name: plantsuite-ppgc-pgbackrest-secrets
#      jobs:
#        restartPolicy: OnFailure
#        backoffLimit: 2
#        priorityClassName: high-priority
#        ttlSecondsAfterFinished: 60
#        resources:
#          limits:
#            cpu: 200m
#            memory: 128Mi
#          requests:
#            cpu: 150m
#            memory: 120Mi
#        tolerations:
#        - effect: NoSchedule
#          key: role
#          operator: Equal
#          value: connection-poolers
#
#        securityContext:
#          fsGroup: 1001
#          runAsUser: 1001
#          runAsNonRoot: true
#          fsGroupChangePolicy: "OnRootMismatch"
#          runAsGroup: 1001
#          seLinuxOptions:
#            type: spc_t
#            level: s0:c123,c456
#          seccompProfile:
#            type: Localhost
#            localhostProfile: localhost/profile.json
#          supplementalGroups:
#          - 1001
#          sysctls:
#          - name: net.ipv4.tcp_keepalive_time
#            value: "600"
#          - name: net.ipv4.tcp_keepalive_intvl
#            value: "60"
#
#      global:
#        repo1-retention-full: "14"
#        repo1-retention-full-type: time
#        repo1-path: /pgbackrest/postgres-operator/plantsuite-ppgc/repo1
#        repo1-cipher-type: aes-256-cbc
#        repo1-s3-uri-style: path
#        repo2-path: /pgbackrest/postgres-operator/plantsuite-ppgc-multi-repo/repo2
#        repo3-path: /pgbackrest/postgres-operator/plantsuite-ppgc-multi-repo/repo3
#        repo4-path: /pgbackrest/postgres-operator/plantsuite-ppgc-multi-repo/repo4
#      repoHost:
#        sidecars:
#        - name: testcontainer
#          image: busybox:latest
#          command: ["sleep", "30d"]
#          securityContext: {}
#        - name: testcontainer2
#          image: mycontainer1:latest
#        resources:
#          limits:
#            cpu: 200m
#            memory: 128Mi
#          requests:
#            cpu: 150m
#            memory: 120Mi
#        affinity:
#          podAntiAffinity:
#            preferredDuringSchedulingIgnoredDuringExecution:
#             - weight: 1
#               podAffinityTerm:
#                 labelSelector:
#                   matchLabels:
#                     postgres-operator.crunchydata.com/data: pgbackrest
#                 topologyKey: kubernetes.io/hostname
#        tolerations:
#        - effect: NoSchedule
#          key: role
#          operator: Equal
#          value: connection-poolers
#        priorityClassName: high-priority
#
#        topologySpreadConstraints:
#        - maxSkew: 1
#          topologyKey: my-node-label
#          whenUnsatisfiable: ScheduleAnyway
#          labelSelector:
#            matchLabels:
#              postgres-operator.crunchydata.com/pgbackrest: ""
#
#        securityContext:
#          fsGroup: 1001
#          runAsUser: 1001
#          runAsNonRoot: true
#          fsGroupChangePolicy: "OnRootMismatch"
#          runAsGroup: 1001
#          seLinuxOptions:
#            type: spc_t
#            level: s0:c123,c456
#          seccompProfile:
#            type: Localhost
#            localhostProfile: localhost/profile.json
#          supplementalGroups:
#          - 1001
#          sysctls:
#          - name: net.ipv4.tcp_keepalive_time
#            value: "600"
#          - name: net.ipv4.tcp_keepalive_intvl
#            value: "60"
#
      manual:
        repoName: repo1
        options:
         - --type=full
#        initialDelaySeconds: 120
      repos:
      - name: repo1
        schedules:
          full: "0 0 * * 6"
#          differential: "0 1 * * 1-6"
#          incremental: "0 1 * * 1-6"
        volume:
          volumeClaimSpec:
#            storageClassName: standard
            accessModes:
            - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
#      - name: repo2
#        s3:
#          bucket: "<YOUR_AWS_S3_BUCKET_NAME>"
#          endpoint: "<YOUR_AWS_S3_ENDPOINT>"
#          region: "<YOUR_AWS_S3_REGION>"
#      - name: repo3
#        gcs:
#          bucket: "<YOUR_GCS_BUCKET_NAME>"
#      - name: repo4
#        azure:
#          container: "<YOUR_AZURE_CONTAINER>"
#
#      restore:
#        repoName: repo1
#        tolerations:
#        - effect: NoSchedule
#          key: role
#          operator: Equal
#          value: connection-poolers

  pmm:
    enabled: false
    image: docker.io/percona/pmm-client:3.4.1
#    imagePullPolicy: IfNotPresent
    secret: plantsuite-ppgc-pmm-secret
    serverHost: monitoring-service
#    resources:
#      limits:
#        memory: 200M
#        cpu: 350m
#      requests:
#        memory: 150M
#        cpu: 300m
#    customClusterName: "<string>"
#    postgresParams: "<string>"
#    querySource: pgstatmonitor
#  patroni:
#    # Some values of the Liveness/Readiness probes of the patroni container are calculated using syncPeriodSeconds by the following formulas:
#    # - timeoutSeconds:   syncPeriodSeconds / 2;
#    # - periodSeconds:    syncPeriodSeconds;
#    # - failureThreshold: leaderLeaseDurationSeconds / syncPeriodSeconds.
#    syncPeriodSeconds: 10 # default: 10
#    leaderLeaseDurationSeconds: 30 # default: 30
#    dynamicConfiguration:
#      postgresql:
#        parameters:
#          restore_command: "pgbackrest --stanza=db archive-get %f \"%p\""
#          max_parallel_workers: 2
#          max_worker_processes: 2
#          shared_buffers: 1GB
#          work_mem: 2MB
#    createReplicaMethods:
#    - pgbackrest
#    - basebackup

#  extensions:
#    image: docker.io/percona/percona-postgresql-operator:2.8.0
#    imagePullPolicy: IfNotPresent
#    storage:
#      type: s3
#      bucket: pg-extensions
#      region: eu-central-1
#      endpoint: s3.eu-central-1.amazonaws.com
#      forcePathStyle: false
#      disableSSL: false
#      secret:
#        name: plantsuite-ppgc-extensions-secret
#    builtin:
#      pg_stat_monitor: true
#      pg_stat_statements: false
#      pg_audit: true
#      pgvector: false
#      pg_repack: false
#    custom:
#    - name: pg_cron
#      version: 1.6.1
